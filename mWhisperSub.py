#!/usr/bin/env python
"""
Realtime Whisper â†’ SRT å­—å¹•å·¥å…·ï¼ˆ2025-07-30  C-full  - å¼·åŒ–é™¤éŒ¯ç‰ˆï¼‰
================================================================
â€¢  æ”¯æ´ `--sr auto`ï¼šä¾åºå˜—è©¦ã€Œä½¿ç”¨è€…æŒ‡å®š â†’  è£ç½®é è¨­ â†’  48000 Hzã€ã€‚
â€¢  VAD çµ±ä¸€åœ¨ 48 kHz åŸ·è¡Œï¼›è‹¥è£ç½®é 48 k/32 k/16 k/8 kï¼Œå…ˆé‡æ¡æ¨£çµ¦ VADã€‚
â€¢  `--device` ç¾åœ¨çœŸæ­£ç”Ÿæ•ˆï¼Œä¸¦è‡ªå‹•æª¢æŸ¥è£ç½®èƒ½åŠ›ã€‚
â€¢  ç¨‹å¼ç¢¼é‡æ–°åˆ†å€å¡Šï¼Œä¾¿æ–¼ç¶­è­·èˆ‡é–±è®€ã€‚
â€¢  æ–°å¢ realtime å­—å¹•ç­–ç•¥ï¼Œå¯å³æ™‚ä¿®æ­£é¡¯ç¤ºã€‚

å»ºè­°æŒ‡ä»¤ï¼š
```bash
python mWhisperSub_reorganized.py --sr auto --lang zh --zh t2tw --vad_gain 5
```
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Imports & Typing
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from __future__ import annotations

import argparse
import csv
import json
import logging
import os
import queue
import threading
import time
import subprocess
import sys
import math
from collections import deque
from datetime import timedelta
from pathlib import Path
from difflib import SequenceMatcher
from typing import Deque, List, Tuple, Any
import re
import zlib

from srt_utils import drop_covered_blocks

import numpy as np
import scipy.signal as ss
import sounddevice as sd
import srt
import unicodedata as ud
import webrtcvad
from faster_whisper import WhisperModel
from transformers import pipeline
from huggingface_hub import login as hf_login
try:
    import torch
except Exception as e:  # pragma: no cover - informative error
    raise RuntimeError(
        "PyTorch 2.6 or newer is required; please install an appropriate version"
    ) from e
from packaging import version

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Global State & Constants (mutable ones are initialised later)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SUPPORTED_VAD_SR = {8000, 16000, 32000, 48000}
STYLE_ECHO_KEYWORDS: Tuple[str, ...] = (
    "ç¹é«”ä¸­æ–‡", "è¯·ä»¥ç¹ä½“", "è«‹ä»¥ç¹é«”", "ä¸è¦ä½¿ç”¨ç°¡é«”", "ä¸è¦ä½¿ç”¨ç®€ä½“", "å°ç£ç”¨èª", "å°æ¹¾ç”¨è¯­",
)

seen_speech = False               # æ˜¯å¦æ›¾åµæ¸¬åˆ°èªéŸ³ï¼ˆå½±éŸ¿è§¸ç™¼ç­–ç•¥ï¼‰
samples_total = 0                 # å·²æ”¶æ¨£æœ¬è¨ˆæ•¸
samples_lock = threading.Lock()
audio_t0: float | None = None     # ADC æ™‚åŸº
audio_origin: float | None = None # çµ¦ SRT çš„é›¶æ™‚æ¨™
_punct_re = re.compile(r"[ï¼Œã€‚ï¼Ÿï¼ï¼›ã€,.!?;:â€¦]")

conf_thr_base = 0.4
conf_thr_max = 0.8
conf_thr = conf_thr_base
CONF_THR_STEP = 0.02

# è®€å–å…±ç”¨è¨­å®š
ROOT_DIR = Path(__file__).resolve().parent
CONFIG = json.loads((ROOT_DIR / "Config.json").read_text(encoding="utf-8"))
MODEL_PATH = ROOT_DIR / CONFIG.get("model_path", "models")
MODEL_PATH.mkdir(parents=True, exist_ok=True)
# Hub caches live directly under `CACHE_PATH`; set `HF_HOME` to its parent
# so both transformers and huggingface_hub use this directory without
# triggering deprecation warnings.
DEFAULT_CACHE = Path.home() / ".cache" / "huggingface" / "hub"
CACHE_PATH = Path(CONFIG.get("cache_path", str(DEFAULT_CACHE))).expanduser().resolve()
CACHE_PATH.mkdir(parents=True, exist_ok=True)
os.environ.setdefault("HF_HOME", str(CACHE_PATH.parent))
MIN_TORCH = version.parse("2.6")
_REPO_MAP = CONFIG["MODEL_REPO_MAP"]
TRANSLATE_MODEL_MAP = {
    tuple(k.split("-")): v for k, v in CONFIG["TRANSLATE_REPO_MAP"].items()
}

# 3. â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parser = argparse.ArgumentParser(description="Realtime Whisperâ†’SRT è½‰å¯«å™¨")
# 3-1 æ¨¡å‹èˆ‡è£ç½®
parser.add_argument("--model_dir", default="medium")
parser.add_argument("--gpu", type=int, default=0, help="<0=CPU, 0+=GPU index")
parser.add_argument("--compute_type", default="int8_float16",
                    choices=["int8", "int8_float16", "float16", "float32"])

# 3-2 éŸ³è¨Šè¼¸å…¥
parser.add_argument("--device", type=int, default=-1,
                    help="éŸ³è¨Šè£ç½® indexï¼ˆ-1=ç³»çµ±é è¨­ï¼›å¯é…åˆ --list-devicesï¼‰")
parser.add_argument("--list-devices", action="store_true")
parser.add_argument("--sr", default="auto",
                    help="è¼¸å…¥å–æ¨£ç‡ï¼š8000/16000/32000/48000 æˆ– 'auto' è‡ªå‹•åˆ¤æ–·")
parser.add_argument("--dtype", default="int16", choices=["int16", "float32"])

# 3-3 è½‰å¯« & åˆ†æ®µåƒæ•¸
parser.add_argument("--lang", default="zh")
parser.add_argument("--translate", action="store_true")
parser.add_argument(
    "--translate_lang",
    choices=["ja", "en", "ko", "zh"],
    help="translation target language; only effective with --translate",
)
parser.add_argument("--win", type=float, default=4, help="åˆ†æè¦–çª—ç§’æ•¸")
parser.add_argument("--maxhop", type=float, default=2.0, help="æœ€é•· MAXHOP é–“éš”")
parser.add_argument("--silence", type=float, default=0.3, help="éœéŸ³å¥é–“éš”ä¸‹é™")
parser.add_argument("--beam", type=int, default=3)
parser.add_argument("--best_of", type=int, default=1)
parser.add_argument("--min_chars", type=int, default=9)
parser.add_argument("--max_chars", type=int, default=16)
parser.add_argument("--min_infer_gap", type=float, default=0.8)
parser.add_argument("--conf-base", type=float, default=0.4,
                    help="baseline word confidence threshold")
parser.add_argument("--conf-max", type=float, default=0.8,
                    help="maximum word confidence threshold")
parser.add_argument("--logprob-thr", type=float, default=-1.0,
                    help="minimum avg logprob to keep segment; -1 disables")
parser.add_argument("--compression-ratio-thr", type=float, default=2.4,
                    help="maximum compression ratio before filtering")
parser.add_argument("--temperature", default="0",
                    help="comma-separated temperatures for fallback decoding")
parser.add_argument("--freq-list",
                    help="optional word frequency list for filtering")
parser.add_argument("--max-unk", type=float, default=1.0,
                    help="max allowed ratio of unknown words (0-1)")
parser.add_argument("--input_file")
parser.add_argument("--output")

# 3-4 ç†±è© / VAD / é™¤éŒ¯
parser.add_argument("--hotwords_file")
parser.add_argument("--vad_gain", type=float, default=5.0,
                    help="èªéŸ³é–€æª» = noise_floor Ã— vad_gain")
parser.add_argument("--noise_decay", type=float, default=0.98)
parser.add_argument("--noise_decay_speech", type=float, default=0.999)
parser.add_argument("--vad_level", type=int, default=1, choices=[0, 1, 2, 3])
parser.add_argument("--auto-vad", action="store_true", help="å•Ÿç”¨è‡ªå‹• VAD æ¨¡å¼")
parser.add_argument("--mic-thr", type=float, default=0.0,
                    help="éŸ³é‡é–¾å€¼ï¼Œå°æ–¼æ­¤å€¼è¦–ç‚ºéœéŸ³ (0~1)")
parser.add_argument("--debug_csv")
parser.add_argument("--dbg_every", type=int, default=4)
parser.add_argument("--log", type=int, default=0, help="0=INFO 1=è©³ç´° 2=DEBUG")
parser.add_argument("--force_silence", action="store_true",help="å¿½ç•¥å‹•æ…‹éœéŸ³ç«‹å³è§¸ç™¼")

# 3-5 å¯«æª”ç­–ç•¥ / ä¸­æ–‡æ­£è¦åŒ–
parser.add_argument("--write_strategy", default="truncate", choices=["truncate", "replace"])
parser.add_argument("--fsync", action="store_true")
parser.add_argument("--zh", default="s2twp", choices=["none", "t2tw", "s2t", "s2twp"])

# 3-6 SRTè¼¸å‡º
parser.add_argument("--srt_path", default="live.srt",
                    help="è¼¸å‡º SRT æª”æ¡ˆå®Œæ•´è·¯å¾‘ï¼Œé è¨­ç‚º live.srt")
args = parser.parse_args()
AUTO_VAD = args.auto_vad
TEMPERATURES = [float(t) for t in args.temperature.split(",") if t.strip()]
freq_words: set[str] = set()
if args.freq_list:
    try:
        with open(args.freq_list, "r", encoding="utf-8") as f:
            freq_words = {ln.strip() for ln in f if ln.strip()}
    except Exception as e:
        print(f"[è©é »] ç„¡æ³•è®€å– {args.freq_list}: {e}")

# è‹¥ä¸æ˜¯ç¾æœ‰ç›®éŒ„ï¼Œå„ªå…ˆä½¿ç”¨ Config æŒ‡å®šçš„ model_path
if not os.path.isdir(args.model_dir):
    local_dir = MODEL_PATH / args.model_dir.replace("/", "--")
    if local_dir.is_dir():
        args.model_dir = str(local_dir)
    else:
        mapped = _REPO_MAP.get(args.model_dir, args.model_dir)
        if mapped != args.model_dir:
            print(f"[æ¨¡å‹] å·²æ˜ å°„ï¼š{args.model_dir} â†’ {mapped}")
            args.model_dir = mapped
if args.list_devices:
    print(sd.query_devices())
    raise SystemExit

_translate_pair: tuple[str, str] | None = None
_use_translate_task = False
if args.translate:
    if args.translate_lang == "en":
        _use_translate_task = True
    else:
        pair = (args.lang, args.translate_lang)
        if args.lang == "auto":
            _use_translate_task = True
            pair = ("en", args.translate_lang)
            TRANSLATE_MODEL_MAP[pair] = "facebook/m2m100_418M"
        elif pair not in TRANSLATE_MODEL_MAP:
            _use_translate_task = True
            pair = ("en", args.translate_lang)
        _translate_pair = pair

conf_thr_base = args.conf_base
conf_thr_max = args.conf_max
conf_thr = conf_thr_base

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Logging & CSV debug
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log_lvl = logging.DEBUG if args.log >= 2 else logging.INFO
logging.basicConfig(level=log_lvl,
                    format="%(asctime)s %(levelname)s: %(message)s",
                    datefmt="%H:%M:%S")
log = logging.getLogger("whisper")
logging.getLogger("huggingface_hub").setLevel(logging.INFO)
logging.getLogger("filelock").setLevel(logging.INFO)

csv_fp = None
csv_writer: csv.writer | None = None
if args.debug_csv:
    csv_fp = open(args.debug_csv, "w", newline="", encoding="utf-8")
    csv_writer = csv.writer(csv_fp)
    csv_writer.writerow(["ts", "rms", "noise", "thr", "vad_flag", "speech", "dyn_sil", "reason"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Utility functions â€“ text length & echo detection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def char_len(text: str) -> float:
    """Return display length (ASCII=0.5  å…¨å½¢=1)"""
    return sum(0.5 if ud.east_asian_width(c) in ("Na", "H", "N", "A") else 1 for c in text)


def split_segment(words, mn: int, mx: int):
    buf: List = []
    ln = 0.0
    st: float | None = None
    out: List[Tuple[float, float, str]] = []
    for w in words:
        if st is None:
            st = w.start
        buf.append(w)
        ln += char_len(w.word)
        if ln >= mn and (ln >= mx or w.word.endswith("ï¼Œã€‚ï¼Ÿï¼ï¼›â€¦")):
            out.append((st, w.end, "".join(x.word for x in buf).strip()))
            buf, ln, st = [], 0.0, None
    if buf:
        out.append((st, buf[-1].end, "".join(x.word for x in buf).strip()))
    return out


def is_style_echo(text: str) -> bool:
    return any(k in text for k in STYLE_ECHO_KEYWORDS)


def is_prompt_echo(text: str, hotwords: List[str]) -> bool:
    if not hotwords or not text:
        return False
    punct = bool(_punct_re.search(text))
    toks = text.strip().split()
    ratio_tok = sum(1 for t in toks if t in hotwords) / len(toks) if toks else 0
    s = _punct_re.sub("", text.replace(" ", ""))
    mask = [False] * len(s)
    for w in hotwords:
        pos = 0
        while (idx := s.find(w, pos)) != -1:
            mask[idx:idx + len(w)] = [True] * len(w)
            pos = idx + 1
    ratio_cov = sum(mask) / len(s) if s else 0
    return ((ratio_tok >= 0.8) or (ratio_cov >= 0.8)) and (not punct or len(s) <= 12)


def compression_ratio(text: str) -> float:
    data = text.encode("utf-8")
    if not data:
        return 0.0
    return len(data) / len(zlib.compress(data))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Model loading & Chinese normalization
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_model():
    device = "cpu" if args.gpu < 0 else "cuda"
    device_index = None if args.gpu < 0 else args.gpu
    return WhisperModel(args.model_dir, device=device, device_index=device_index, compute_type=args.compute_type)

model = load_model()

try:
    import opencc
    _cc_cache: dict[str, opencc.OpenCC] = {}

    def _get_cc(mode: str):
        if mode == "none":
            return None
        if mode not in _cc_cache:
            _cc_cache[mode] = opencc.OpenCC(mode)
            print(f"[OpenCC] æ¨¡å¼={mode} å¯ç”¨=True")
        return _cc_cache[mode]
except Exception:  # pragma: no cover
    def _get_cc(mode: str):  # type: ignore
        print(f"[OpenCC] æ¨¡å¼={mode} å¯ç”¨=False")
        return None


def zh_norm(text: str) -> str:
    cc = _get_cc(args.zh)
    if not cc:
        return text
    try:
        return cc.convert(text)
    except Exception:
        return text


_translate_pipes: dict[tuple[str, str], Any] = {}


def _prompt_hf_token() -> bool:
    """Prompt the user for a Hugging Face token via GUI or CLI."""
    try:
        from PyQt5 import QtWidgets  # type: ignore
    except Exception:  # pragma: no cover
        QtWidgets = None  # type: ignore

    if QtWidgets and QtWidgets.QApplication.instance():  # pragma: no cover - requires GUI
        class TokenDialog(QtWidgets.QDialog):
            def __init__(self):
                super().__init__()
                self.setWindowTitle("Hugging Face Login")
                layout = QtWidgets.QVBoxLayout(self)
                label = QtWidgets.QLabel(
                    '<a href="https://huggingface.co/settings/tokens">Get your Hugging Face token</a>'
                )
                label.setOpenExternalLinks(True)
                layout.addWidget(label)
                self.edit = QtWidgets.QLineEdit()
                self.edit.setEchoMode(QtWidgets.QLineEdit.Password)
                layout.addWidget(self.edit)
                buttons = QtWidgets.QDialogButtonBox(
                    QtWidgets.QDialogButtonBox.Ok | QtWidgets.QDialogButtonBox.Cancel
                )
                buttons.accepted.connect(self.accept)
                buttons.rejected.connect(self.reject)
                layout.addWidget(buttons)

        dlg = TokenDialog()
        if dlg.exec_() != QtWidgets.QDialog.Accepted or not dlg.edit.text():
            return False
        token = dlg.edit.text()
        try:
            hf_login(token)
        except Exception as exc:
            QtWidgets.QMessageBox.warning(None, "Hugging Face Login", str(exc))
            return False
        QtWidgets.QMessageBox.information(None, "Hugging Face Login", "Login successful")
        return True

    if sys.stdin.isatty():
        print("translation model requires a HuggingFace token")
        print("Get one at https://huggingface.co/settings/tokens")
        try:
            subprocess.run(["huggingface-cli", "login"], check=True)
        except Exception:  # pragma: no cover
            print("run 'huggingface-cli login' in another terminal")
            input("Press Enter after completing login to retry...")
        return True

    log.warning("translation model requires authentication but no GUI or TTY is available")
    return False


def _load_translate_pipe(src: str, tgt: str):
    pair = (src, tgt)
    pipe = _translate_pipes.get(pair)
    if pipe is None:
        model = TRANSLATE_MODEL_MAP.get(pair)
        if model is None:
            return None
        if model.startswith("facebook/") and version.parse(torch.__version__.split("+")[0]) < MIN_TORCH:
            log.warning(
                "translation model %s requires PyTorch %s+; found %s",
                model,
                MIN_TORCH,
                torch.__version__,
            )
            _translate_pipes[pair] = None
            return None
        kwargs = {}
        if model.startswith("facebook/m2m100"):
            kwargs["src_lang"] = src
            kwargs["tgt_lang"] = tgt
        elif model.startswith("facebook/nllb"):
            nllb = {"ja": "jpn_Jpan", "ko": "kor_Hang", "zh": "zho_Hans"}
            kwargs["src_lang"] = nllb[src]
            kwargs["tgt_lang"] = nllb[tgt]
        local = MODEL_PATH / model.replace("/", "--")
        if local.is_dir():
            model = str(local)
        while True:
            try:
                pipe = pipeline("translation", model=model, **kwargs)
                break
            except Exception as exc:  # pragma: no cover - runtime dependency
                err = str(exc)
                if "401" in err or "token" in err.lower():
                    if _prompt_hf_token():
                        continue
                    log.warning(
                        "translation model %s requires authentication: %s",
                        model,
                        exc,
                    )
                    pipe = None
                    break
                log.warning("translation model %s unavailable: %s", model, exc)
                pipe = None
                break
        _translate_pipes[pair] = pipe
    return pipe


def translate_text(text: str, src: str, tgt: str) -> str:
    pipe = _load_translate_pipe(src, tgt)
    if pipe is None:
        return text
    try:
        return pipe(text, max_length=400)[0]["translation_text"]
    except Exception as exc:  # pragma: no cover - runtime dependency
        log.warning("translation %sâ†’%s failed: %s", src, tgt, exc)
        return text

# Pre-load translation model before starting transcription so any
# authentication prompts appear early.
if args.translate and _translate_pair:
    _load_translate_pipe(*_translate_pair)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. Hotwords monitoring
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_hotwords: List[str] = []
_hotwords_mtime: float | None = None


def _load_hotwords(path: str) -> List[str]:
    try:
        ws = Path(path).read_text(encoding="utf-8").strip().split()
        ws = [w for w in ws if len(w) >= 2]
        return [zh_norm(w) for w in ws]
    except FileNotFoundError:
        return []


def _update_hotwords():
    global _hotwords, _hotwords_mtime
    if not args.hotwords_file:
        return
    try:
        mt = os.path.getmtime(args.hotwords_file)
    except FileNotFoundError:
        if _hotwords:
            _hotwords, _hotwords_mtime = [], None
        return
    if _hotwords_mtime != mt:
        _hotwords = _load_hotwords(args.hotwords_file)
        _hotwords_mtime = mt
        log.info("hotwords æ›´æ–°: %s", _hotwords)


def get_prompt() -> str | None:
    _update_hotwords()
    return " ".join(_hotwords) if _hotwords else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. Single-file transcription mode (exit after done)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if args.input_file:
    transcribe_args = {
        "language": args.lang,
        "beam_size": args.beam,
        "best_of": args.best_of,
        "word_timestamps": True,
        "initial_prompt": get_prompt(),
    }
    if _use_translate_task:
        transcribe_args["task"] = "translate"
    segs, _ = model.transcribe(args.input_file, **transcribe_args)
    subs = []
    for i, s in enumerate(segs, 1):
        txt = s.text.strip()
        if args.translate:
            if _translate_pair:
                txt = translate_text(txt, *_translate_pair)
                if _translate_pair[1] == "zh":
                    txt = zh_norm(txt)
            else:
                pass
        else:
            txt = zh_norm(txt)
        if is_style_echo(txt) or is_prompt_echo(txt, _hotwords):
            continue
        subs.append(srt.Subtitle(i, timedelta(seconds=s.start), timedelta(seconds=s.end), txt))
    out_path = args.output or Path(args.input_file).with_suffix(".srt")
    Path(out_path).write_text(srt.compose(subs), encoding="utf-8-sig")
    raise SystemExit

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. Realtime (streaming) mode â€“ audio initialisation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DTYPE = args.dtype

# 9-1 Open audio stream with fallback logic
SR_REQ = None if str(args.sr).lower() == "auto" else int(args.sr)
DEV = None if args.device < 0 else args.device


def audio_cb(indata, frames, t, status):
    if status:
        log.warning(status)
    pcm = np.frombuffer(indata, dtype=DTYPE)
    if DTYPE == "float32":
        pcm = np.clip(pcm * 32768, -32768, 32767).astype(np.int16)
    with buf_lock:
        buffer.extend(pcm)
    global samples_total, audio_t0
    with samples_lock:
        samples_total += frames
        if audio_t0 is None:
            audio_t0 = getattr(t, "inputBufferAdcTime", time.monotonic())


def open_stream(dev, sr_preferred):
    """Return (FS_IN, stream) with fallback."""
    try:
        default_sr = int(sd.query_devices(dev or sd.default.device[0], "input")['default_samplerate'])
    except Exception:
        default_sr = None
    candidates = [sr_preferred, default_sr, 48000]
    for sr in [c for c in candidates if c]:
        try:
            sd.check_input_settings(device=dev, samplerate=sr, channels=1, dtype=DTYPE)
            stream = sd.RawInputStream(samplerate=sr, channels=1, dtype=DTYPE, device=dev, callback=audio_cb)
            return sr, stream
        except Exception as e:
            log.debug("open_stream: %s @ %s Hz failed â€“ %s", dev, sr, e)
    raise RuntimeError("ç„¡æ³•é–‹å•Ÿä»»ä½•å–æ¨£ç‡ï¼Œè«‹æª¢æŸ¥è£ç½®æˆ–æ¬Šé™")

try:
    FS_IN, istream = open_stream(DEV, SR_REQ)
    istream.start()
except Exception as e:
    log.error("éŸ³è¨Šä¸²æµå•Ÿå‹•å¤±æ•—: %s", e)
    raise SystemExit(1)

# 9-2 Derived audio constants (now that FS_IN is final)
FS_OUT = 16000            # Whisper å›ºå®š 16 kHz
FS_VAD = 48000            # VAD å›ºå®š 48 kHz
WIN_S = args.win
MAXHOP_S = args.maxhop
VAD_FRAME_MS = 10
frame_len = int(FS_IN * VAD_FRAME_MS // 1000)
vad = webrtcvad.Vad(args.vad_level)

# 9-3 Buffers & queues
buffer: Deque[np.int16] = deque(maxlen=int(FS_IN * WIN_S))
buf_lock = threading.Lock()
infer_q: queue.Queue[Tuple[np.ndarray, float, str]] = queue.Queue(maxsize=3)
write_q: queue.Queue[dict] = queue.Queue(maxsize=64)

last_vad_speech = 0.0; last_trigger_ts = 0.0; last_trigger_aud = 0.0
noise_floor: float | None = None
pause_hist: Deque[float] = deque(maxlen=30)
last_state = False; last_change_ts = 0.0
speech_hist: Deque[Tuple[float, float]] = deque()
speech_peak = 0.0

DEDUP_WIN = 3.0; SIM_THR = 0.85; MERGE_WIN = 1.0

if FS_IN not in SUPPORTED_VAD_SR:
    log.warning("è£ç½®æ¡æ¨£ç‡ %d Hz ä¸æ˜¯ VAD æ”¯æ´å€¼ï¼Œå°‡è‡ªå‹•é‡æ¡æ¨£åˆ° 48k", FS_IN)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. Helpers â€“ audio timeline & energy
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def audio_now() -> float:
    with samples_lock:
        base = audio_t0 or 0.0
        return base + (samples_total / float(FS_IN))


def rms_energy(pcm: np.ndarray) -> float:
    return float(np.sqrt(np.mean(pcm.astype(np.float32) ** 2)) + 1e-7)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 11. Trigger worker â€“ VAD + MAXHOP
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def trigger_worker():
    global last_vad_speech, last_trigger_ts, last_trigger_aud, last_state
    global noise_floor, last_change_ts, seen_speech, audio_origin, conf_thr
    global speech_peak

    TAIL_KEEP_S = 2.0  # keep 2 seconds before trigger for context
    poll_s = 0.05
    tick = 0
    dropped_infer = 0
    prev_mono = time.monotonic()

    while True:
        time.sleep(poll_s)
        mono = time.monotonic()
        dt = max(0.0, min(0.25, mono - prev_mono))
        prev_mono = mono
        anow = audio_now()

        if audio_origin is None:
            audio_origin = anow

        with buf_lock:
            if len(buffer) < FS_IN:
                continue
            samples = np.array(buffer, dtype=np.int16)
        frame = samples[-frame_len:]
        frame_f32 = frame.astype(np.float32) / 32768.0

        # å‹•æ…‹é›œè¨Šä¼°è¨ˆèˆ‡èªéŸ³å³°å€¼è¿½è¹¤
        rms = rms_energy(frame)
        if noise_floor is None:
            noise_floor = rms
        else:
            decay = args.noise_decay if not last_state else args.noise_decay_speech
            alpha_eff = decay ** dt
            noise_floor = alpha_eff * noise_floor + (1 - alpha_eff) * rms

        speech_hist.append((mono, rms))
        while speech_hist and mono - speech_hist[0][0] > 15.0:
            speech_hist.popleft()
        if speech_hist:
            speech_peak = max(r for _, r in speech_hist)

        # é–€æª» + VAD åˆ¤æ–·
        thr = args.mic_thr or 0.0
        if args.auto_vad:
            dyn_range = max(0.0, speech_peak - (noise_floor or 0.0))
            thr = max(thr, (noise_floor or 0.0) + dyn_range * 0.2)
        else:
            thr = max(thr, (noise_floor or 0.0) * args.vad_gain)
        pcm_for_vad = frame_f32
        if FS_IN != FS_VAD:
            pcm_for_vad = ss.resample_poly(frame_f32, FS_VAD, FS_IN)
        is_vad = vad.is_speech((pcm_for_vad * 32768).astype(np.int16).tobytes(), FS_VAD)
        speech = bool(is_vad or (rms > thr))
        if speech:
            conf_thr = max(conf_thr_base, conf_thr - CONF_THR_STEP)
        else:
            conf_thr = min(conf_thr_max, conf_thr + CONF_THR_STEP)

        dyn_sil = max(args.silence, (np.median(pause_hist) * 0.6) if pause_hist else args.silence)
        if args.force_silence:
            dyn_sil = 0.0

        # ç‹€æ…‹åˆ‡æ›
        if speech != last_state:
            if last_change_ts:
                pause_hist.append(max(0.08, min(2.0, mono - last_change_ts)))
            last_change_ts, last_state = mono, speech
        if speech:
            last_vad_speech, seen_speech = mono, True

        reason = None
        if seen_speech:
            if not speech and (mono - last_vad_speech) >= dyn_sil:
                reason = "VAD"
            elif speech and (anow - last_trigger_aud) >= max(MAXHOP_S, args.min_infer_gap):
                reason = "MAXHOP"

        if args.log >= 2 and tick % args.dbg_every == 0:
            log.debug("rms %.1f  noise %.1f  thr %.1f  vad %d  speech %d  dyn_sil %.2f",
                      rms, noise_floor, thr, int(is_vad), int(speech), dyn_sil)
        if csv_writer and reason:
            csv_writer.writerow([time.time(), rms, noise_floor, thr, int(is_vad), int(speech), dyn_sil, reason])
        tick += 1
        if reason is None:
            continue

        # å–å‡ºæ•´æ®µ audio ä¸Ÿæ¨ç†
        with buf_lock:
            seg = np.array(buffer, dtype=np.int16)
            buffer.clear()
            tail = seg[-int(FS_IN * TAIL_KEEP_S):]
            if len(tail):
                buffer.extend(tail)
        seg_rms = rms_energy(seg)
        if noise_floor is not None and seg_rms < noise_floor * 1.1:
            continue
        try:
            infer_q.put_nowait((seg, anow, reason))
        except queue.Full:
            # æ»¿äº†å…ˆæ¨æ£„æœ€èˆŠçš„ MAXHOP æ®µ
            tmp = []
            dropped = False
            while not infer_q.empty():
                item = infer_q.get_nowait(); infer_q.task_done()
                if not dropped and item[2] == "MAXHOP":
                    dropped = True; continue
                tmp.append(item)
            for it in tmp:
                infer_q.put_nowait(it)
            if not dropped and infer_q.full():
                infer_q.get_nowait(); infer_q.task_done()
            infer_q.put_nowait((seg, anow, reason))
            dropped_infer += 1
            if args.log >= 2 and dropped_infer % 50 == 0:
                log.debug("infer_q drops=%d", dropped_infer)

        last_trigger_aud, last_trigger_ts = anow, time.time()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 12. Consumer worker â€“ Whisper inference & segmentation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_lock = threading.Lock()


def consumer_worker():
    dropped_write = 0
    while True:
        _update_hotwords()
        seg_int16, end_ts, reason = infer_q.get()
        try:
            pcm_f = seg_int16.astype(np.float32) / 32768.0
            if FS_IN != FS_OUT:
                pcm_f = ss.resample_poly(pcm_f, FS_OUT, FS_IN)
            seg_len = len(pcm_f) / FS_OUT
            seg_rms = rms_energy(seg_int16)

            use_prompt = None
            if _hotwords:
                if args.auto_vad:
                    dyn_range = max(0.0, speech_peak - (noise_floor or 0.0))
                    dyn_thr = (noise_floor or 0.0) + dyn_range * 0.2
                else:
                    dyn_thr = (noise_floor or 0.0) * max(1.5, args.vad_gain * 0.25)
                if (seg_len >= 0.7 or reason == "VAD") and (seg_rms > dyn_thr):
                    use_prompt = " ".join(_hotwords)

            with model_lock:
                segments = []
                for temp in TEMPERATURES:
                    transcribe_args = {
                        "language": args.lang,
                        "beam_size": args.beam,
                        "best_of": args.best_of,
                        "condition_on_previous_text": False,
                        "word_timestamps": True,
                        "initial_prompt": use_prompt,
                        "temperature": temp,
                    }
                    if _use_translate_task:
                        transcribe_args["task"] = "translate"
                    segments, _ = model.transcribe(pcm_f, **transcribe_args)
                    if segments:
                        break

            origin = audio_origin or 0.0
            for seg in segments:
                no_speech = getattr(seg, "no_speech_prob", 0.0)
                if (
                    noise_floor is not None
                    and seg_rms < noise_floor * 1.1
                    and no_speech < 0.4
                ):
                    if args.log >= 1:
                        log.info(
                            "skip low-energy segment rms=%.4f no_speech_prob=%.2f",
                            seg_rms,
                            no_speech,
                        )
                    continue
                avg_log = getattr(seg, "avg_logprob", 0.0)
                if args.logprob_thr > -1.0 and avg_log < args.logprob_thr:
                    continue
                words = [w for w in seg.words if w.probability >= conf_thr]
                if not words:
                    continue
                for st, et, raw_txt in split_segment(words, args.min_chars, args.max_chars):
                    if (
                        args.compression_ratio_thr > 0
                        and compression_ratio(raw_txt) > args.compression_ratio_thr
                    ):
                        continue
                    txt = raw_txt.strip()
                    if args.translate:
                        if _translate_pair:
                            txt = translate_text(txt, *_translate_pair)
                            if _translate_pair[1] == "zh":
                                txt = zh_norm(txt)
                        else:
                            pass
                    else:
                        txt = zh_norm(txt)
                    if is_style_echo(txt) or is_prompt_echo(txt, _hotwords):
                        continue
                    if freq_words:
                        toks = re.findall(r"\w+", txt)
                        if toks:
                            unk = sum(1 for t in toks if t not in freq_words) / len(toks)
                            if unk > args.max_unk:
                                continue
                    start = (end_ts - seg_len + st) - origin
                    end = (end_ts - seg_len + et) - origin
                    rec = {"start": max(0.0, start), "end": end, "text": txt, "reason": reason}
                    try:
                        write_q.put_nowait(rec)
                    except queue.Full:
                        write_q.get_nowait(); write_q.task_done()
                        write_q.put_nowait(rec)
                        dropped_write += 1
                        if args.log >= 2 and dropped_write % 50 == 0:
                            log.debug("write_q drops=%d", dropped_write)
        finally:
            infer_q.task_done()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 13. Writer â€“ dedup / merge / SRT file output
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _similar(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()


def flush(live: List[dict]):
    outp = Path(args.srt_path)
    data = srt.compose([
        srt.Subtitle(i + 1, timedelta(seconds=r["start"]), timedelta(seconds=r["end"]), r["text"])
        for i, r in enumerate(live[-800:])
    ])
    if args.write_strategy == "replace":
        tmp = outp.with_suffix(outp.suffix + ".tmp")
        try:
            tmp.write_text(data, encoding="utf-8-sig")
            os.replace(tmp, outp)
        except PermissionError:
            with open(outp, "w", encoding="utf-8-sig", newline="") as f:
                f.write(data)
                if args.fsync:
                    f.flush(); os.fsync(f.fileno())
            try:
                tmp.unlink()
            except Exception:
                pass
    else:
        with open(outp, "w", encoding="utf-8-sig", newline="") as f:
            f.write(data)
            if args.fsync:
                f.flush(); os.fsync(f.fileno())


def writer():
    live: List[dict] = []
    sliding: List[dict] = []
    FLUSH_EVERY = 0.10
    last_flush = time.monotonic()
    while True:
        rec = write_q.get(); now = rec["start"]

        live = drop_covered_blocks(live, rec)
        sliding = drop_covered_blocks(sliding, rec)

        # 1) replace or skip exact duplicates
        if live:
            last = live[-1]
            if (
                math.isclose(rec["start"], last["start"], abs_tol=1e-3)
                and math.isclose(rec["end"], last["end"], abs_tol=1e-3)
            ):
                if rec["text"] == last["text"]:
                    write_q.task_done(); continue
                live[-1] = rec
                sliding[-1] = rec
                flush(live); last_flush = time.monotonic()
                write_q.task_done(); continue
            if rec["text"] == last["text"]:
                write_q.task_done(); continue
            if abs(rec["start"] - last["start"]) < DEDUP_WIN:
                if rec["text"].startswith(last["text"]):
                    live[-1] = rec
                    sliding[-1] = rec
                    flush(live); last_flush = time.monotonic()
                    write_q.task_done(); continue
                if last["text"].startswith(rec["text"]):
                    write_q.task_done(); continue

        # 2) similarity dedup
        if any(
            _similar(rec["text"], s["text"]) >= SIM_THR
            and abs(rec["start"] - s["start"]) < DEDUP_WIN
            for s in sliding
        ):
            write_q.task_done(); continue

        # 3) merge MAXHOP back-to-back
        if live:
            last = live[-1]
            if (
                rec["reason"] == "MAXHOP"
                and last["reason"] == "VAD"
                and 0 < rec["start"] - last["start"] < MERGE_WIN
                and rec["text"].startswith(last["text"])
            ):
                last.update(text=rec["text"], end=rec["end"], reason="MERGE")
                sliding.append(last)
                flush(live); last_flush = time.monotonic()
                write_q.task_done(); continue

        # 4) append & maintain sliding window
        live.append(rec); sliding.append(rec)
        sliding = [s for s in sliding if now - s["start"] < DEDUP_WIN]

        # 5) flush conditions
        if any(rec["text"].endswith(p) for p in "ã€‚ï¼ï¼Ÿâ€¦") or rec["reason"] == "MERGE":
            flush(live); last_flush = time.monotonic()
        elif time.monotonic() - last_flush >= FLUSH_EVERY:
            flush(live); last_flush = time.monotonic()

        write_q.task_done()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 14. Thread startup & main loop
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
threading.Thread(target=trigger_worker, daemon=True).start()
threading.Thread(target=consumer_worker, daemon=True).start()
threading.Thread(target=writer, daemon=True).start()

print("ğŸŸ¢ å³æ™‚å­—å¹•é–‹å§‹ â€¢ Ctrl+C çµæŸ")
try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    print(f"\nâ¹ï¸  åœæ­¢ï¼ŒSRT ä¿å­˜åœ¨ {args.srt_path}")
finally:
    if csv_fp:
        csv_fp.close()
